---
title: "Test 2"
output:
  pdf_document: default
  html_notebook: default
fontsize: 9pt
---


Loading the packages first
```{r setoptions, echo=TRUE, message=FALSE, warning=FALSE}

library(pacman)
    p_load(tidyverse,dplyr, lavaan, psych, knitr, lme4, lmerTest, multilevel, nlme, lattice, sjPlot, ggplot2,cowplot, magrittr, broom, Metrics, pbkrtest, mlmRev, influence.ME, gridExtra, semPlot, plyr, kableExtra, ICC, irr,  lapply )
    
```
                      
                      Question 1 â€“ Structural Equation Modeling

loading data
```{r loaddata, mysize = TRUE, message = FALSE, size="\\scriptsize"}

data <- readRDS("peru2.RDS")  

```

Making variables for the path analysis for SEM. I would like to predict risky/antisocial behaviour using self-efficacy, early life SES (round 1 and 2), mental health and agency
```{r}

#   SES (Using the following variables: Housing quality, Access to services, Consumer durables)
    data$hq_r12<-data$hq_r12/3
    data$sv_r12<-data$sv_r12/3
    data$cd_r12<-data$cd_r12/3
    data$ses_scale<-data$hq_r12+data$sv_r12+data$cd_r12
    
#   self-efficacy
    data$self_eff1<-(data$self_eff1)/8    
    data$self_eff2<-(data$self_eff2)/8  
    data$self_eff3<-(data$self_eff3)/8
    data$self_eff4<-(data$self_eff4)/8
    data$self_eff5<-(data$self_eff5)/8
    data$self_eff6<-(data$self_eff6)/8
    data$self_eff7<-(data$self_eff7)/8
    data$self_eff8<-(data$self_eff8)/8
    data$self_efficacy_scale<-(data$self_eff1 + data$self_eff2 + data$self_eff3 + data$self_eff4 + data$self_eff5 + data$self_eff6 + data$self_eff7 + data$self_eff8)
    
#   agency
    data$agency1<-data$agency1/4
    data$agency2<-data$agency2/4
    data$agency3<-data$agency3/4
    data$agency4<-data$agency4/4
    data$agency_scale<-data$agency1+data$agency2+data$agency3+data$agency4
    
#   mental wellness
    data$sdq1<-data$sdq1/5
    data$sdq2<-data$sdq2/5
    data$sdq3<-data$sdq3/5
    data$sdq4<-data$sdq4/5
    data$sdq5<-data$sdq5/5
    data$mental_wellness_scale<-data$sdq1+data$sdq2+data$sdq3+data$sdq4+data$sdq5
    
#   anti-social, or risk-taking behaviour at Round 5 
    
    data$FRNSMKR5<-data$FRNSMKR5/9 #Have friends who smoke   
    data$FRNALCR5<-data$FRNALCR5/9 #Have friends who use alcohol
    data$YOUALCR5<-data$YOUALCR5/9 #Uses alcohol 
    data$BEATEN<-data$BEATEN/9     #Beaten up by friends, strangers, teachers, parents 
    data$ARRSTDR5<-data$ARRSTDR5/9 #Has been arrested
    data$FRNGNGR5<-data$FRNGNGR5/9 #Has friends in gang
    data$MEMGNGR5<-data$MEMGNGR5/9 #Is a member of a gang
    data$CRYWPNR5<-data$CRYWPNR5/9 #Has carried a weapon
    data$NUMPRTR5<-data$NUMPRTR5/9 #Number of sex partners had
    data$risky_behaviour_scale<-(data$FRNSMKR5 + data$FRNALCR5 + data$YOUALCR5 + data$BEATEN + data$ARRSTDR5 + data$FRNGNGR5 + data$MEMGNGR5 + data$CRYWPNR5 + data$NUMPRTR5)
```
 Defining path model
```{r}

pathm1 <- '
      risky_behaviour_scale ~ self_efficacy_scale
      mental_wellness_scale ~ self_efficacy_scale

'
#Fitting and summarising the model
prejpathfit1 <- sem(pathm1, data = data)
summary(prejpathfit1, fit.measures = T) 

```
 
CFI and TLI are > .09 which shows that the model has a good fit, The model is  shows a good fit, not too sure about the RMSEA, p-value =Na, might need to compare to another model


Now drawing model using package semPlot
```{r}
semPlot::semPaths(prejpathfit1, what = "est", layout = "spring")
```
Our model is telling us that self efficacy and mental wellness are predictors of risky behaviours with self-efficacy also predicting mental illness

Defining path model 2

```{r predicttree, mysize = TRUE, warning=FALSE,  size="\\scriptsize", fig.height=3}

pathm2 <- '
      risky_behaviour_scale ~ self_efficacy_scale + mental_wellness_scale
      mental_wellness_scale ~ self_efficacy_scale + agency_scale
      self_efficacy_scale ~  agency_scale 

'  

#Fitting and summarising model
prejpathfit2 <- sem(pathm2, data = data)
summary(prejpathfit2, fit.measures = T) 

#comparing this model to our first model
anova(prejpathfit2, prejpathfit1) 
```

Now plotting this model
```{r}
semPlot::semPaths(prejpathfit2, what = "est", layout = "spring")
```
Let's take a closer look at the residuals as our new model as the AIC is higher than the first model's one and the RMSEA p-value is not significant
```{r}
      resid(prejpathfit2, type = "normalized")
      modificationindices(prejpathfit2)

```
we can see correlation between the risky behaviour scale and the mental wellness and self-efficacy scales
now lets respecify the model to allow correlations between the error terms in each scale 
```{r mysize = TRUE, warning=FALSE,  size="\\scriptsize"}
  
  prejpathmodel2 <- '
                # MEASUREMENT MODEL
                  agency_scale =~ agency1 + agency2 + agency3 + agency4
                  self_efficacy_scale =~ self_eff1 + self_eff2 + self_eff3 + self_eff4 + self_eff5 + self_eff6                   + self_eff7 + self_eff8
                  mental_wellness_scale =~ sdq1 + sdq2 + sdq3 + sdq4 + sdq5
                  risky_behaviour_scale =~ FRNSMKR5 + FRNALCR5 + YOUALCR5 + BEATEN + ARRSTDR5 + FRNGNGR5 +                      MEMGNGR5 + CRYWPNR5 + NUMPRTR5

      
                # STRUCTURAL MODEL
                  risky_behaviour_scale ~ self_efficacy_scale + mental_wellness_scale
                  mental_wellness_scale ~ self_efficacy_scale + agency_scale
                  self_efficacy_scale ~  agency_scale 
                  
                # CORRELATED ERRORS
                  risky_behaviour_scale	~~	mental_wellness_scale
                  risky_behaviour_scale	~~	self_efficacy_scale
      
               '
#Fitting and summarising model
 prejpathfit3 <- sem(prejpathmodel2, data = data)
      summary(prejpathfit3, fit.measures = T)

```
  Although the RMSEA, SRMR and AIC/BIC are suggestive of a better fitting model, the RMSEA p-value is 1???

Now plotting this model

```{r}

semPlot::semPaths(prejpathfit3, what = "est", layout = "spring")
```
With the correlated errors we can see that the riscky behaviour scale is not linked to any of the other variables
Let's see waht happens if the correlated errors are excluded
```{r}
prejpathmodel3 <- '
                # MEASUREMENT MODEL
                  agency_scale =~ agency1 + agency2 + agency3 + agency4
                  self_efficacy_scale =~ self_eff1 + self_eff2 + self_eff3 + self_eff4 + self_eff5 + self_eff6                   + self_eff7 + self_eff8
                  mental_wellness_scale =~ sdq1 + sdq2 + sdq3 + sdq4 + sdq5
                  risky_behaviour_scale =~ FRNSMKR5 + FRNALCR5 + YOUALCR5 + BEATEN + ARRSTDR5 + FRNGNGR5 +                      MEMGNGR5 + CRYWPNR5 + NUMPRTR5

      
                # STRUCTURAL MODEL
                  risky_behaviour_scale ~ self_efficacy_scale + mental_wellness_scale
                  mental_wellness_scale ~ self_efficacy_scale + agency_scale
                  self_efficacy_scale ~  agency_scale 
                  
               
               '
#Fitting and summarising model
 prejpathfit4 <- sem(prejpathmodel3, data = data)
      summary(prejpathfit4, fit.measures = T)

```
The summary is still the same as that of the previous model, now let's see the diagram

```{r}
semPlot::semPaths(prejpathfit4, what = "est", layout = "spring")
```
We can now see that the risky behaviour scale is now icluded in the relationship tree. The model shows that agency is a predictor of both self-efficacy and mental wellnenss, and mental illness is in turn a predictor of risky behaviour
```{r warning= FALSE}
#COMPARE models 2 and 3
    anova(prejpathfit2, prejpathfit3)
```


                                Question 2 Mixed-Effects Models
2.1
Loading datasets
```{r}
ethp  <- load("YL_June2017_Ethiopiadata_2017-09-08")
india <- load("YL_June2017_Indiadata_2017-11-22")
peru  <- load("YL_June2017_perudata_2017-11-12")
viet  <- load("YL_June2017_Vietnamdata_2017-11-01")
```
Now merging datasets


```{r message = FALSE}
mylist <- list( one=Ethiopia.dat, two=India.dat, three=peru.dat, four= Vietnam.dat )
joined <- join_all( mylist, type="full" ) 
```
2.1 Making new dataset with only the necessary variables

First added the suggested variables then adding the other variables that were found to have a relationship with cognitive development in the articles (in this case measured through receptive vocan - ppvt), these include : parents education, stunting, type of preschool
```{r message= FALSE, warning= FALSE} 
newdata <- joined %>% 
  dplyr::select(childid, ppvtraw, wi, round, agemon, sex, typesite, bmi, bwght, zhfa, caredu,stunt,preschool_type) %>% 
  group_by(childid) %>% 
 
 
```
a Summary Statistics
```{r}
str(newdata,  na = "NaN") #we can see that some of our varibles need to be changed to factors

```

```{r}

newdata$round  <-as.factor(newdata$round) 
newdata$sex    <-  as.factor(newdata$sex) 
newdata$preschool_type <- as.factor(newdata$preschool_type) 
newdata$wi <- as.numeric(newdata$wi)

```

```{r message=FALSE, warning=FALSE}
#now some descriptive stats grouping by stunting where 1 = stunted and 0 = no stunting
newdata %>% 
  dplyr:: select(-childid) %>% #this refused to work
  describeBy(group = newdata$stunt, mat = T, na.rm = TRUE) #also missing values are stubborn
  
```
We can see that the non-stunted children had higher receptive vocab scores than those who were stunted
let's look at receptive vocab and wealth index

```{r  message= FALSE, warning= FALSE}
newdata %>% 
  dplyr:: select(childid, round, ppvtraw, wi) %>% 
  filter(round != 1) %>% 
   ggplot(mapping = aes(x = wi, y = as.numeric(ppvtraw), group = round)) + 
  geom_point(size = 0.5, alpha = 1) + 
  geom_smooth(method = "lm") +
  facet_wrap(~round) +
  labs(title = "Relationship between wealth index and receptive vocabulary", 
         subtitle = "Per round(2005, 2009, 2012, 2015)", 
         x = "Wealth Index", y = "Receptive Vocabulary") +
  theme_minimal()
```
We can see that the receptive vocab incereses as the children get older and also that those with lower wealth index have lower receptive vocab scores

Let's expore the relationship between receptive vocab and parent education
```{r message= FALSE, warning= FALSE}
newdata %>% 
  dplyr:: select(childid, round, ppvtraw, caredu) %>% 
  filter(round != 1) %>% 
   ggplot(mapping = aes(x = caredu, y = as.numeric(ppvtraw), group = round)) + 
  geom_point(size = 0.5, alpha = 1) + 
  geom_smooth(method = "lm") +
  facet_wrap(~round) +
  labs(title = "Relationship between parental education and receptive vocabulary", 
         subtitle = "Per round(2005, 2009, 2012, 2015)", 
         x = "Parent education", y = "Receptive Vocabulary") +
  theme_minimal()
```
there isnt much of a relationship here

Let's explore some more potential relationship graphically to see mixed effects

```{r plot data, echo= FALSE, message=FALSE, warning=FALSE}

ggplot(newdata, aes(x = as.factor(stunt), y = ppvtraw, 
  fill = preschool_type, na.exclude)) +
  geom_bar(position=position_dodge(), stat = 'identity') +
  facet_grid(. ~ round)+
  theme_bw(base_size = 14)+
  xlab("Stunting (0 = no, 1 = yes")+
  ylab("receptive vocab")
```
The missing values are messing with the analyses big time (- _ -)Can't continue with descriptive stats with thme behaving like this 

b  Yes there is a need to include random effects to the model as the individuals sampled in the datasets are from  an infinite population of possible individuals, observations are nested within groups, it's repeated measures data
c ICC

```{r warning=FALSE, message= FALSE}
 coeff <- ICC(newdata )
  print(coeff)
```

3  Using the top-down approach, construct a mixed-effects model from your chosen variables.

```{r  warning=FALSE, message= FALSE}
#linear model
ppvt_lm <- lm(ppvtraw ~ stunt + wi + sex, 
              data = newdata, na.rm = TRUE)

mse(predict(ppvt_lm), newdata$ppvtraw)


```
Inspect residuals

```{r}
#residual plot
bwplot(childid ~ resid(ppvt_lm), newdata, 
       xlab = "Residuals for linear model", ylab = "ppvtraw")
```
```{r echo=FALSE}


#null model nlme
ppvt_lme0_lmer <- lmer(ppvtraw ~1 + (1|round),
data = newdata)
mse(predict(math_lme0_lmer), newdata$ppvtraw)

```
```{r}
ppvt_lme1 <- lmer(ppvtraw ~ wi + stunt + sex + (1|round),
data = newdata)
#compare AICs
AIC(ppvt_lme1, ppvt_lm)
```
our new model's AIC is lower than the lm's so suggests better fit

```{r}
summary(ppvt_lme1)$coef
```
full model with lmer
```{r}
ppvt_lme2 <- lmer(ppvtraw ~ wi + stunt + sex + (wi|round), data = newdata)
AIC(ppvt_lme2)
```

  the AIC of this newer model is lower
`
